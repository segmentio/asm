// Code generated by command: go run std_asm.go -pkg base64 -out ../base64/std_amd64.s -stubs ../base64/std_amd64.go. DO NOT EDIT.

#include "textflag.h"

DATA stdEncMask<>+0(SB)/8, $0x8000000000000000
DATA stdEncMask<>+8(SB)/8, $0x8000000080000000
DATA stdEncMask<>+16(SB)/8, $0x8000000080000000
DATA stdEncMask<>+24(SB)/8, $0x8000000080000000
GLOBL stdEncMask<>(SB), RODATA|NOPTR, $32

DATA stdEncShfl<>+0(SB)/8, $0x0809070805060405
DATA stdEncShfl<>+8(SB)/8, $0x0e0f0d0e0b0c0a0b
DATA stdEncShfl<>+16(SB)/8, $0x0405030401020001
DATA stdEncShfl<>+24(SB)/8, $0x0a0b090a07080607
GLOBL stdEncShfl<>(SB), RODATA|NOPTR, $32

DATA stdEncAnd1<>+0(SB)/8, $0x003f03f0003f03f0
DATA stdEncAnd1<>+8(SB)/8, $0x003f03f0003f03f0
DATA stdEncAnd1<>+16(SB)/8, $0x003f03f0003f03f0
DATA stdEncAnd1<>+24(SB)/8, $0x003f03f0003f03f0
GLOBL stdEncAnd1<>(SB), RODATA|NOPTR, $32

DATA stdEncAnd2<>+0(SB)/8, $0x0fc0fc000fc0fc00
DATA stdEncAnd2<>+8(SB)/8, $0x0fc0fc000fc0fc00
DATA stdEncAnd2<>+16(SB)/8, $0x0fc0fc000fc0fc00
DATA stdEncAnd2<>+24(SB)/8, $0x0fc0fc000fc0fc00
GLOBL stdEncAnd2<>(SB), RODATA|NOPTR, $32

DATA stdEncMult<>+0(SB)/8, $0x0400004004000040
DATA stdEncMult<>+8(SB)/8, $0x0400004004000040
DATA stdEncMult<>+16(SB)/8, $0x0400004004000040
DATA stdEncMult<>+24(SB)/8, $0x0400004004000040
GLOBL stdEncMult<>(SB), RODATA|NOPTR, $32

DATA stdEncTabl<>+0(SB)/8, $0xfcfcfcfcfcfc4741
DATA stdEncTabl<>+8(SB)/8, $0x0000f0edfcfcfcfc
DATA stdEncTabl<>+16(SB)/8, $0xfcfcfcfcfcfc4741
DATA stdEncTabl<>+24(SB)/8, $0x0000f0edfcfcfcfc
GLOBL stdEncTabl<>(SB), RODATA|NOPTR, $32

// func stdEncodeAVX2(dst []byte, src []byte) (int, int)
// Requires: AVX, AVX2, SSE4.1
TEXT Â·stdEncodeAVX2(SB), NOSPLIT, $0-64
	MOVQ         dst_base+0(FP), AX
	MOVQ         src_base+24(FP), DX
	MOVQ         src_len+32(FP), SI
	XORQ         CX, CX
	XORQ         BX, BX
	MOVB         $0x33, DI
	PINSRB       $0x00, DI, X1
	VPBROADCASTB X1, Y1
	MOVB         $0x19, DI
	PINSRB       $0x00, DI, X2
	VPBROADCASTB X2, Y2
	VMOVDQU      stdEncTabl<>+0(SB), Y3

	// Load the first block using a mask to avoid potential fault
	VMOVDQU    stdEncMask<>+0(SB), Y0
	VPMASKMOVD -4(DX)(BX*1), Y0, Y0

loop:
	VPSHUFB  stdEncShfl<>+0(SB), Y0, Y0
	VPAND    stdEncAnd1<>+0(SB), Y0, Y4
	VPSLLW   $0x08, Y4, Y5
	VPSLLW   $0x04, Y4, Y4
	VPBLENDW $0xaa, Y5, Y4, Y4
	VPAND    stdEncAnd2<>+0(SB), Y0, Y5
	VPMULHUW stdEncMult<>+0(SB), Y5, Y5
	VPOR     Y5, Y4, Y0
	VPSUBUSB Y1, Y0, Y5
	VPCMPGTB Y2, Y0, Y4
	VPSUBB   Y4, Y5, Y5
	VPSHUFB  Y5, Y3, Y4
	VPADDB   Y0, Y4, Y0
	VMOVDQU  Y0, (AX)(CX*1)
	ADDQ     $0x20, CX
	ADDQ     $0x18, BX
	SUBQ     $0x18, SI
	CMPQ     SI, $0x20
	JB       done
	VMOVDQU  -4(DX)(BX*1), Y0
	JMP      loop

done:
	MOVQ CX, ret+48(FP)
	MOVQ BX, ret1+56(FP)
	RET
